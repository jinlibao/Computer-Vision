{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnimalsDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.transform = transform\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.dataset[0][idx], self.dataset[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch tutorial\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 64)\n",
    "        self.fc2 = nn.Linear(64, 16)\n",
    "        self.fc3 = nn.Linear(16, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rosebrock\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv = nn.Conv2d(3, 32, 3, 1, 1)\n",
    "        self.fc = nn.Linear(32 * 32 * 32, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv(x))\n",
    "        x = x.view(-1, 32 * 32 * 32)\n",
    "        x = F.softmax(self.fc(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(root_dir):\n",
    "    data, labels = [], []\n",
    "    classes = os.listdir(root_dir)\n",
    "    paths = [os.path.join(root_dir, c) for c in classes]\n",
    "    for path in paths:\n",
    "        files = os.listdir(path)\n",
    "        filenames = [os.path.join(path, file) for file in files]\n",
    "        for filename in filenames:\n",
    "            img = cv2.imread(filename)\n",
    "            image = cv2.resize(img, (32, 32), interpolation=cv2.INTER_AREA)\n",
    "            # for PyTorch\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "            data.append(image.astype('float') / 255.0)\n",
    "            # labels.append(files[0].split('_')[0])\n",
    "            labels.append(classes.index(files[0].split('_')[0]))\n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(data, labels, test_size=0.32, random_state=42)\n",
    "    # Y_train = LabelBinarizer().fit_transform(y_train).argmax(axis=1)\n",
    "    # Y_test = LabelBinarizer().fit_transform(y_test).argmax(axis=1)\n",
    "    trainset = (X_train, Y_train)\n",
    "    testset = (X_test, Y_test)\n",
    "    return (trainset, testset, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(root_dir):\n",
    "    # Load image and split data into trainset and testset\n",
    "    trainset, testset, classes = read_image(root_dir)\n",
    "    trainset, testset = AnimalsDataset(trainset), AnimalsDataset(testset)\n",
    "    trainloader = DataLoader(trainset, batch_size=4, shuffle=False, num_workers=2)\n",
    "    testloader = DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "    \n",
    "    # Instantiate CNN, pick loss function and optimizer\n",
    "    net = Net().float()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.95) # lr: 1e-1, 1e-2, 1e-3, 1e-4; momentum: 0.9-0.99\n",
    "\n",
    "    # Training in 50 epochs\n",
    "    epochs = 50\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            # print(type(inputs), type(labels), inputs.shape)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs.float())\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print('[info] epoch {:2d}, loss: {:8.3f}'.format(epoch + 1, running_loss))\n",
    "    print('Finished training.')\n",
    "    PATH = './animals.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "    print('Saving trained model to {:s}'.format(PATH))\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    class_correct = [0. for i in range(3)]\n",
    "    class_total = [0. for i in range(3)]\n",
    "    acc = [0. for i in range(3)]\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images.float())\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(3):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "    for i in range(3):\n",
    "        acc[i] = 100 * class_correct[i] / class_total[i]\n",
    "    \n",
    "    # Generate classification report\n",
    "    with torch.no_grad():\n",
    "        images, labels = list(zip(*testset))\n",
    "        outputs = net(torch.Tensor(images).float())\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        report = classification_report(labels, predicted, target_names=classes)\n",
    "    \n",
    "    return (trainset, testset, trainloader, testloader, classes, acc, report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/Users/libao/Documents/data/animals/'\n",
    "trainset, testset, trainloader, testloader, classes, accuracies, report = CNN(root_dir)\n",
    "\n",
    "for i, acc in enumerate(accuracies):\n",
    "    print('Accuracy of {:5s} : {:.2f} %'.format(classes[i], acc))\n",
    "print('Classification report:\\n', report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(labels.shape)\n",
    "print(labels)\n",
    "print(images[0].shape)    \n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(images[0].dtype)\n",
    "print(' '.join('{:5s}'.format(classes[labels[j]]) for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './animals.pth'\n",
    "torch.save(net.state_dict(), PATH)\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('{:5s}'.format(classes[labels[j]]) for j in range(4)))\n",
    "\n",
    "net = Net().float()\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "outputs = net(images.float())\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "print('Predicted: ', ' '.join('{:5s}'.format(classes[predicted[j]]) for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images.float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of the network on the test images: {:f} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alexnet = torchvision.models.alexnet(pretrained=True)\n",
    "# vgg16 = torchvision.models.vgg16(pretrained=True)\n",
    "# resnet101 = torchvision.models.resnet101(pretrained=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
