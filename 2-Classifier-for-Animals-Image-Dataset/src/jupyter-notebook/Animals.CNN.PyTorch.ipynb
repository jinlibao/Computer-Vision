{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch tutorial\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 64)\n",
    "        self.fc2 = nn.Linear(64, 16)\n",
    "        self.fc3 = nn.Linear(16, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        # x = F.softmax(self.fc3(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rosebrock\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv = nn.Conv2d(3, 32, 3, 1, 1)\n",
    "        self.fc = nn.Linear(32 * 32 * 32, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv(x))\n",
    "        x = x.view(-1, 32 * 32 * 32)\n",
    "        x = F.softmax(self.fc(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnimalsDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image= self.dataset[0][idx]\n",
    "        target = self.dataset[1][idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return [image, target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(root_dir, test_size=0.25, validation_size=0.1, batch_size=32, transform=None):\n",
    "    # Read images and labels\n",
    "    data, labels = [], []\n",
    "    classes = [c for c in os.listdir(root_dir) if not c.startswith('.')]\n",
    "    paths = [os.path.join(root_dir, c) for c in classes]\n",
    "    for path in paths:\n",
    "        files = os.listdir(path)\n",
    "        filenames = [os.path.join(path, file) for file in files]\n",
    "        data.extend([Image.open(f).convert('RGB') for f in filenames])\n",
    "        labels.extend([classes.index(f.split('_')[0]) for f in files])\n",
    "    \n",
    "    # Split data into trainset and testset\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(data, labels, test_size=test_size, random_state=42)\n",
    "    trainset = (X_train, Y_train)\n",
    "    testset = (X_test, Y_test)\n",
    "\n",
    "    # Transform RGB image to torch.Tensor\n",
    "    if not transform:\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((32, 32)), # resize all the image to 32x32x3\n",
    "            transforms.ToTensor(),       # rescale images from [0, 255] to [0, 1.0], (H x W x C) to (C x H x W)\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # rescale [0, 1.0] to [-1.0, 1.0]\n",
    "        ])\n",
    "    trainset, testset = AnimalsDataset(trainset, transform), AnimalsDataset(testset, transform)\n",
    "\n",
    "    # Create DataLoader for trainset and testset\n",
    "    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    return (trainloader, testloader, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(dataset, epochs=50, lr=1e2, momentum=8.5e-1, dest='../../trained_model'):\n",
    "    trainloader, testloader, classes = dataset\n",
    "    batch_size = trainloader.batch_size\n",
    "    # Instantiate CNN, pick loss function and optimizer\n",
    "    net = Net()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum) # lr: 1e-1, 1e-2, 1e-3, 1e-4; momentum: 0.9-0.99\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for train_batch in trainloader:\n",
    "            images, targets = train_batch\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() / batch_size\n",
    "        print('[epoch {:02d}/{:2d}] loss: {:5.3f}'.format(epoch + 1, epochs, running_loss))\n",
    "    print('Finished training.')\n",
    "    if not os.path.exists(dest):\n",
    "        os.mkdir(dest)\n",
    "    model_filename = '{:s}/animals_{:.1e}_{:.1e}_{:d}.pth'.format(dest, lr, momentum, epochs)\n",
    "    torch.save(net.state_dict(), model_filename)\n",
    "    print('Saving trained model to {:s}'.format(model_filename))\n",
    "\n",
    "    # Calculate the accuracy and generate classification report\n",
    "    number_of_classes = len(classes)\n",
    "    with torch.no_grad():\n",
    "        class_correct = [0. for i in range(number_of_classes)]\n",
    "        class_total = [0. for i in range(number_of_classes)]\n",
    "        acc = [0. for i in range(number_of_classes)]\n",
    "        predicts_total, targets_total = [], []\n",
    "        for test_batch in testloader:\n",
    "            images, targets = test_batch\n",
    "            outputs = net(images)\n",
    "            _, predicts = torch.max(outputs, 1)\n",
    "            predicts_total.extend(predicts.numpy())\n",
    "            targets_total.extend(targets.numpy())\n",
    "            c = (predicts == targets).squeeze()\n",
    "            for i, target in enumerate(targets):\n",
    "                class_correct[target] += c[i].item()\n",
    "                class_total[target] += 1\n",
    "        report = classification_report(targets_total, predicts_total, target_names=classes)\n",
    "\n",
    "        for i in range(3):\n",
    "            acc[i] = 100 * class_correct[i] / class_total[i]\n",
    "        \n",
    "    return (report, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/Users/libao/Documents/data/animals/'\n",
    "dataset = read_image(root_dir)\n",
    "trainloader, testloader, classes = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "learning_rates = [1e-1, 1e-2,1e-3, 1e-4]\n",
    "momentums = torch.arange(0.8, 1.00, 0.05)\n",
    "\n",
    "batch_size = 32\n",
    "for lr in learning_rates:\n",
    "    for momentum in momentums:\n",
    "        print('learning rate: {:e}, momentumn: {:e}'.format(lr, momentum))\n",
    "        report, accuracies = CNN(dataset=dataset, epochs=epochs, lr=lr, momentum=momentum)\n",
    "\n",
    "        # for i, acc in enumerate(accuracies):\n",
    "        #     print('Accuracy of {:5s} : {:.2f} %'.format(classes[i], acc))\n",
    "        print('Classification report:\\n', report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image):\n",
    "    image = image / 2 + 0.5\n",
    "    \n",
    "    # Method 1\n",
    "    image_pil = transforms.ToPILImage()(image)\n",
    "    plt.imshow(image_pil)\n",
    "    \n",
    "    # # Method 2\n",
    "    # image_np = image.numpy()\n",
    "    # plt.imshow(np.transpose(image_np, (1, 2, 0)))\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((32,32)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "# ])\n",
    "# image = Image.open('{:s}/cats/cats_00001.jpg'.format(root_dir))\n",
    "# image = transform(image)\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(labels.shape)\n",
    "print(labels)\n",
    "print(images[0].shape)    \n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(images[0].dtype)\n",
    "print(' '.join('{:5s}'.format(classes[labels[j]]) for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('{:5s}'.format(classes[labels[j]]) for j in range(4)))\n",
    "\n",
    "net = Net().float()\n",
    "PATH = './animals.pth'\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "outputs = net(images.float())\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "print('Predicted: ', ' '.join('{:5s}'.format(classes[predicted[j]]) for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images.float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of the network on the test images: {:f} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alexnet = torchvision.models.alexnet(pretrained=True)\n",
    "# vgg16 = torchvision.models.vgg16(pretrained=True)\n",
    "# resnet101 = torchvision.models.resnet101(pretrained=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
