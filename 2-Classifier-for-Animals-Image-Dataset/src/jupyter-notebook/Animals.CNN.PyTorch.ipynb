{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from PIL import Image, ImageFile\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "%config InlineBackend.figure_formats = ['svg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch tutorial\n",
    "class TorchNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(TorchNet, self).__init__()\n",
    "        self.name = 'TorchNet'\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 64)\n",
    "        self.fc2 = nn.Linear(64, 16)\n",
    "        self.fc3 = nn.Linear(16, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.softmax(self.fc3(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.name = 'LeNet'\n",
    "        self.conv1 = nn.Conv2d(3, 20, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5)\n",
    "        self.fc1 = nn.Linear(50 * 5 * 5, 300)\n",
    "        self.fc2 = nn.Linear(300, 3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 50 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.softmax(self.fc2(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniVGGNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MiniVGGNet, self).__init__()\n",
    "        self.name = 'MiniVGGNet'\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, 1, 1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, 1, 1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, 1, 1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout1 = nn.Dropout2d(p=0.25)\n",
    "        self.dropout2 = nn.Dropout2d(p=0.5)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(32)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(64)\n",
    "        self.batch_norm3 = nn.BatchNorm1d(512)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 64, 512)\n",
    "        self.fc2 = nn.Linear(512, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(F.relu(self.conv1(x)))\n",
    "        x = self.dropout1(self.pool(self.batch_norm1(F.relu(self.conv2(x)))))\n",
    "        x = self.batch_norm2(F.relu(self.conv3(x)))\n",
    "        x = self.dropout1(self.pool(self.batch_norm2(F.relu(self.conv4(x)))))\n",
    "        x = x.view(-1, 8 * 8 * 64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.softmax(self.fc2(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rosebrock\n",
    "class ShallowNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ShallowNet, self).__init__()\n",
    "        self.name = 'ShallowNet'\n",
    "        self.conv = nn.Conv2d(3, 32, 3, 1, 1)\n",
    "        self.fc = nn.Linear(32 * 32 * 32, 3)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv(x))\n",
    "        x = x.view(-1, 32 * 32 * 32)\n",
    "        x = F.softmax(self.fc(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnimalsDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image= self.dataset[0][idx]\n",
    "        target = self.dataset[1][idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return [image, target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNTrainer(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        plt.style.use('ggplot')\n",
    "        plt.rc('text', usetex=False)\n",
    "        plt.rc('font', family='serif')\n",
    "\n",
    "        root_dir = '/Users/libao/Documents/data/animals/'\n",
    "        batch_size = 128\n",
    "        dataset = self.read_image(root_dir, batch_size=batch_size)\n",
    "        self.dataset = dataset\n",
    "        train_loader, validation_loader, test_loader, classes = dataset\n",
    "        self.train_loader = train_loader\n",
    "        self.validation_loader = validation_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.classes = classes\n",
    "    \n",
    "    def imshow(self, image):\n",
    "        image = image / 2 + 0.5\n",
    "        \n",
    "        # Method 1\n",
    "        image_pil = transforms.ToPILImage()(image)\n",
    "        plt.imshow(image_pil)\n",
    "\n",
    "        # # Method 2\n",
    "        # image_np = image.numpy()\n",
    "        # plt.imshow(np.transpose(image_np, (1, 2, 0)))\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def plot(self, df, net_name, learning_rates, momentums):\n",
    "        for lr in learning_rates:\n",
    "            for m in momentums:\n",
    "                d = df[(df['lr'] == lr) & (df['momentum'] == m)]\n",
    "                fig = plt.figure()\n",
    "                plt.plot(d['epoch'], d['acc_train'], label='acc_train')\n",
    "                plt.plot(d['epoch'], d['acc_val'], label='acc_val')\n",
    "                plt.plot(d['epoch'], d['loss_train'], label='loss_train')\n",
    "                plt.plot(d['epoch'], d['loss_val'], label='loss_val')\n",
    "                plt.xlabel('epoch #')\n",
    "                plt.ylabel('loss/accuracy')\n",
    "                plt.title(net_name)\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "                plt.close()\n",
    "            \n",
    "    def read_image(self, root_dir, test_size=0.25, validation_size=0.2, batch_size=32, transform=None):\n",
    "        # Read images and labels\n",
    "        data, labels = [], []\n",
    "        classes = [c for c in os.listdir(root_dir) if not c.startswith('.')]\n",
    "        paths = [os.path.join(root_dir, c) for c in classes]\n",
    "        print('Loading images...')\n",
    "        for path in paths:\n",
    "            files = os.listdir(path)\n",
    "            filenames = [os.path.join(path, file) for file in files]\n",
    "            data.extend([Image.open(f).convert('RGB') for f in filenames])\n",
    "            labels.extend([classes.index(f.split('_')[0]) for f in files])\n",
    "\n",
    "        print('Generating train_set/validation_set/test_set...')\n",
    "        # Split data into train_set, validation_set, and test_set\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(data, labels, test_size=test_size, random_state=42)\n",
    "        X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=validation_size, random_state=42)\n",
    "        train_set = (X_train, Y_train)\n",
    "        validation_set = (X_val, Y_val)\n",
    "        test_set = (X_test, Y_test)\n",
    "\n",
    "        # Transform RGB image to torch.Tensor\n",
    "        if not transform:\n",
    "            transform = transforms.Compose([\n",
    "                transforms.Resize((32, 32)), # resize all the image to 32x32x3\n",
    "                transforms.ToTensor(),       # rescale images from [0, 255] to [0, 1.0], (H x W x C) to (C x H x W)\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # rescale [0, 1.0] to [-1.0, 1.0]\n",
    "            ])\n",
    "\n",
    "        validation_set = AnimalsDataset(validation_set, transform)\n",
    "        train_set = AnimalsDataset(train_set, transform)\n",
    "        test_set = AnimalsDataset(test_set, transform)\n",
    "\n",
    "        # Create DataLoader for train_set, validation_set, and test_set\n",
    "        validation_loader = DataLoader(validation_set, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "        train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "        test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "        return (train_loader, validation_loader, test_loader, classes)\n",
    "    \n",
    "    def get_report(self, net, data_loader):\n",
    "        with torch.no_grad():\n",
    "            predicts_total, targets_total = [], []\n",
    "            for batch in data_loader:\n",
    "                images, targets = batch\n",
    "                outputs = net(images)\n",
    "                _, predicts = torch.max(outputs, 1)\n",
    "                predicts_total.extend(predicts.numpy())\n",
    "                targets_total.extend(targets.numpy())\n",
    "            confusion = confusion_matrix(targets_total, predicts_total)\n",
    "            report_dict = classification_report(targets_total, predicts_total, target_names=self.classes, output_dict=True)\n",
    "            report = classification_report(targets_total, predicts_total, target_names=self.classes)\n",
    "        return (report_dict, report, confusion)\n",
    "    \n",
    "    def model(self, net, data_loader, criterion=None, optimizer=None, mode='eval'):\n",
    "        running_loss = 0.0\n",
    "        for batch in data_loader:\n",
    "            images, targets = batch\n",
    "            if mode == 'train':\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(images)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            else:\n",
    "                outputs = net(images)\n",
    "                loss = criterion(outputs,targets)\n",
    "            running_loss += loss.item() / len(data_loader)\n",
    "        report_dict, _, _ = self.get_report(net, data_loader)\n",
    "\n",
    "        return (running_loss, report_dict['accuracy'])\n",
    "    \n",
    "    def CNN(self, net, dataset, epochs=50, lr=1e-2, momentum=8.5e-1, dest='../../trained_model'):\n",
    "        train_loader, validation_loader, test_loader, classes = dataset\n",
    "        batch_size = train_loader.batch_size\n",
    "        # Instantiate CNN, pick loss function and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum) # lr: 1e-1, 1e-2, 1e-3, 1e-4; momentum: 0.9-0.99\n",
    "\n",
    "        history = []\n",
    "        nets = []\n",
    "        lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            loss_train, acc_train = self.model(net, train_loader, criterion, optimizer, 'train')\n",
    "            lr_scheduler.step()\n",
    "            loss_val, acc_val = self.model(net, validation_loader, criterion)\n",
    "            nets.append(net.state_dict())\n",
    "            history.append({\n",
    "                'epoch': epoch + 1,\n",
    "                'acc_train': acc_train,\n",
    "                'acc_val': acc_val,\n",
    "                'loss_train': loss_train,\n",
    "                'loss_val': loss_val,\n",
    "                'lr': lr,\n",
    "                'momentum': momentum\n",
    "            })\n",
    "            print('[epoch {:2d}/{:2d}] loss_train: {:5.3f}, acc_train: {:5.3f}, loss_val: {:5.3f}, acc_val: {:5.3f}'.format(\n",
    "                epoch + 1, epochs, loss_train, acc_train, loss_val, acc_val))\n",
    "        print('Finished training.')\n",
    "\n",
    "        idx = np.argmax(np.array(pd.DataFrame(history)['acc_val']))\n",
    "        print('The best epoch is {:d}'.format(idx + 1))\n",
    "\n",
    "        if not os.path.exists(dest):\n",
    "            os.mkdir(dest)\n",
    "        model_filename = '{:s}/{:s}_{:.1e}_{:.1e}_{:d}.pth'.format(dest, net.name, lr, momentum, epochs)\n",
    "        print('Saving trained model to {:s}'.format(model_filename))\n",
    "        torch.save(nets[idx], model_filename)\n",
    "\n",
    "        print('Evaluating network at best epoch...')\n",
    "        net.load_state_dict(nets[idx])\n",
    "        # Calculate the accuracy and generate classification report\n",
    "        report_dict, report, confusion = self.get_report(net, test_loader)\n",
    "\n",
    "        return (report_dict, report, confusion, history)\n",
    "    \n",
    "    \n",
    "    def test(self):\n",
    "        train_loader, validation_loader, test_loader, classes = self.dataset\n",
    "        print(len(train_loader) * train_loader.batch_size)\n",
    "        print(len(test_loader) * test_loader.batch_size)\n",
    "        print(len(validation_loader) * validation_loader.batch_size)\n",
    "        \n",
    "        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        epochs = 3\n",
    "        # learning_rates = [1e-1, 1e-2,1e-3, 1e-4]\n",
    "        # momentums = torch.arange(0.8, 1.00, 0.05)\n",
    "        learning_rates = [1e-2]\n",
    "        momentums = [8.5e-1]\n",
    "\n",
    "        nets = [\n",
    "            MiniVGGNet(),\n",
    "            LeNet(),\n",
    "            ShallowNet(),\n",
    "            TorchNet()\n",
    "        ]\n",
    "        \n",
    "        for net in nets:\n",
    "            print('Training {:s}...'.format(net.name))\n",
    "            all_history = []\n",
    "            for lr in learning_rates:\n",
    "                for momentum in momentums:\n",
    "                    dest='../../trained_model/{:s}'.format(net.name)\n",
    "                    print('learning rate: {:e}, momentumn: {:e}'.format(lr, momentum))\n",
    "                    report_dict, report, confusion, history = self.CNN(net, self.dataset, epochs, lr, momentum, dest)\n",
    "                    pd.DataFrame(report_dict).T.to_csv('{:s}/{:s}_{:.1e}_{:.1e}_{:d}_report.csv'.format(dest, net.name, lr, momentum, epochs))\n",
    "                    all_history.extend(history)\n",
    "                    print('Confusion matrix:\\n', confusion)   \n",
    "                    print('Classification report:\\n', report)\n",
    "            df = pd.DataFrame(all_history)\n",
    "            df.to_csv('{:s}/training_history.csv'.format(dest))\n",
    "            self.plot(df, net.name, learning_rates, momentums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ct = CNNTrainer()\n",
    "ct.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((32,32)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "# ])\n",
    "# image = Image.open('{:s}/cats/cats_00001.jpg'.format(root_dir))\n",
    "# image = transform(image)\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(labels.shape)\n",
    "print(labels)\n",
    "print(images[0].shape)    \n",
    "ct.imshow(torchvision.utils.make_grid(images))\n",
    "print(images[0].dtype)\n",
    "print(' '.join('{:5s}'.format(classes[labels[j]]) for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "ct.imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('{:5s}'.format(classes[labels[j]]) for j in range(batch_size)))\n",
    "\n",
    "net = MiniVGGNet()\n",
    "path = '../../trained_model/MiniVGGNet/MiniVGGNet_1.0e-02_8.5e-01_30.pth'\n",
    "net.load_state_dict(torch.load(path))\n",
    "report_dict, report, confusion = get_report(net, test_loader)\n",
    "print(report)\n",
    "outputs = net(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "print('Predicted: ', ' '.join('{:5s}'.format(classes[predicted[j]]) for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alexnet = torchvision.models.alexnet(pretrained=True)\n",
    "# vgg16 = torchvision.models.vgg16(pretrained=True)\n",
    "# resnet101 = torchvision.models.resnet101(pretrained=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
